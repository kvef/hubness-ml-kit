
/**
* Hub Miner: a hubness-aware machine learning experimentation library.
* Copyright (C) 2014  Nenad Tomasev. Email: nenad.tomasev at gmail.com
* 
* This program is free software: you can redistribute it and/or modify it under
* the terms of the GNU General Public License as published by the Free Software
* Foundation, either version 3 of the License, or (at your option) any later
* version.
* 
* This program is distributed in the hope that it will be useful, but WITHOUT
* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
* FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License along with
* this program. If not, see <http://www.gnu.org/licenses/>.
*/
package images.mining.codebook;

import data.representation.DataInstance;
import data.representation.DataSet;
import distances.primary.CombinedMetric;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Random;
import learning.unsupervised.Cluster;
import learning.unsupervised.ClusteringAlg;
import learning.unsupervised.methods.multithreaded.MTFastKMeans;
import util.CommandLineParser;
import util.fileFilters.DirectoryFilter;
import util.fileFilters.DescFileNameFilter;

/**
 * A generic class for calculating image feature codebooks.
 *
 * @author Nenad Tomasev <nenad.tomasev at gmail.com>
 */
public class GenericCodeBookMaker {

    public static final int DEFAULT_SIZE = 400;
    public static final int NUM_THREADS = 8;
    private File target = null;
    private boolean recursive = true;
    private DataSet featureSample = null;
    // The resulting cluster configuration.
    private Cluster[] resultingConfiguration = null;
    // Cluster centroids.
    private DataInstance[] centroids = null;
    // The object used to cluster the features.
    private MTFastKMeans clusterer = null;
    // Metric to use in the feature space.
    private CombinedMetric cmet = CombinedMetric.FLOAT_EUCLIDEAN;
    private HashMap<String, String> tabuPathMap;
    // Descriptor length.
    private int descLen;

    /**
     * @param cmet CombinedMetric object for distance calculations.
     */
    public void setCombinedMetirc(CombinedMetric cmet) {
        this.cmet = cmet;
    }

    /**
     * @return CombinedMetric object for distance calculations.
     */
    public CombinedMetric getCombinedMetric() {
        return cmet;
    }

    /**
     * The main method for generating a codebook.
     *
     * @param args Command line parameters, as specified.
     * @throws Exception
     */
    public static void main(String[] args) throws Exception {
        CommandLineParser clp = new CommandLineParser(true);
        clp.addParam("-featureInput", "Path to the input file containing the "
                + "descriptors or a directory containing files with descriptors"
                + "in files with a 'desc' extension generated by OpenCV.",
                CommandLineParser.STRING, true, false);
        clp.addParam("-outCodebookFile", "Path to where the codebook is to be "
                + "persisted.", CommandLineParser.STRING,
                true, false);
        clp.addParam("-descLength", "Integer that is the descriptor length.",
                CommandLineParser.INTEGER, true, false);
        clp.addParam("-codebookSize", "Integer that is the codebook size.",
                CommandLineParser.INTEGER, true, false);
        clp.addParam("-perc", "Percentage of the features to load for codebook"
                + "generation", CommandLineParser.FLOAT, true, false);
        clp.addParam("-tabu", "File with a newline separated list of files that"
                + "are to be ignored", CommandLineParser.STRING, false, false);
        clp.parseLine(args);
        File inFile = new File((String) clp.getParamValues("-featureInput").
                get(0));
        File outFile = new File((String) clp.getParamValues("-outCodebookFile").
                get(0));
        int descLength = (Integer) clp.getParamValues("-descLength").get(0);
        int codebookSize = (Integer) clp.getParamValues("-codebookSize").get(0);
        float perc = (Float) clp.getParamValues("-perc").get(0);
        GenericCodeBookMaker gcm = new GenericCodeBookMaker(inFile, true,
                descLength);
        gcm.tabuPathMap = new HashMap<>(500);
        if (clp.hasParamValue("-tabu")) {
            gcm.populateTabuMap((String) clp.getParamValues("-tabu").get(0));
        }
        gcm.getFeaturesFromTargetFiles(perc);
        System.out.println("Sampled " + gcm.featureSample.size() + " features");
        gcm.clusterFeatures(codebookSize);
        System.out.println(gcm.resultingConfiguration.length + " clusters.");
        GenericCodeBook generatedCodebook = gcm.getCodeBookVectors();
        System.out.println(generatedCodebook.getSize() + " size.");
        generatedCodebook.writeCodeBookToFile(outFile);
    }

    /**
     * Populates a map of tabued file paths, image representations to ignore.
     *
     * @param inFilePath
     */
    public void populateTabuMap(String inFilePath) throws Exception {
        try (BufferedReader br = new BufferedReader(new InputStreamReader(
                     new FileInputStream(new File(inFilePath))))) {
            String s = br.readLine();
            while (s != null) {
                tabuPathMap.put(s, s);
                s = br.readLine();
            }
        } catch (Exception e) {
            System.err.println(e.getMessage());
        }
    }

    public GenericCodeBookMaker(File target, boolean recursive, int descLen) {
        // If the target is a directory, clustering will be done for all arff
        // files in the directory. If it is a file, only for the given file.
        this.target = target;
        this.recursive = recursive;
        this.descLen = descLen;
        featureSample = new DataSet();
        featureSample.fAttrNames = new String[descLen];
        for (int i = 0; i < descLen; i++) {
            featureSample.fAttrNames[i] = "LocalAtt" + i;
        }
    }

    /**
     * @return ClusteringAlg object used in quantization.
     */
    public ClusteringAlg getClusteringObject() {
        return clusterer;
    }

    /**
     * Perform clustering on the SIFT sample.
     *
     * @throws Exception
     */
    public void clusterFeatures() throws Exception {
        clusterFeatures(DEFAULT_SIZE);
    }

    /**
     * Perform clustering on the local feature sample.
     *
     * @param numClusters Integer that is the number of clusters to generate.
     * @throws Exception
     */
    public void clusterFeatures(int numClusters) throws Exception {
        if ((featureSample == null) || (featureSample.isEmpty())) {
            System.out.println("Empty sample.");
            return;
        }
        clusterer = new MTFastKMeans(featureSample, cmet, numClusters,
                NUM_THREADS, true);
        clusterer.cluster();
        resultingConfiguration = clusterer.getClusters();
        centroids = clusterer.getCentroids();
    }

    /**
     * Get the generated cluster configuration.
     *
     * @return
     */
    public Cluster[] getConfiguration() {
        return resultingConfiguration;
    }

    /**
     * @return DataInstance array of the generated clustering configuration
     * centroids.
     * @throws Exception
     */
    public DataInstance[] getConfigurationCentroids() throws Exception {
        if ((resultingConfiguration == null)
                || resultingConfiguration.length == 0) {
            return new DataInstance[0];
        }
        DataInstance[] clusterCentroids =
                new DataInstance[resultingConfiguration.length];
        for (int i = 0; i < clusterCentroids.length; i++) {
            clusterCentroids[i] = resultingConfiguration[i].getCentroid();
        }
        return clusterCentroids;
    }

    /**
     * @return GenericCodeBook object that corresponds to the generated
     * centroids.
     * @throws Exception
     */
    public GenericCodeBook getCodeBookVectors() throws Exception {
        if ((resultingConfiguration == null)
                || resultingConfiguration.length == 0) {
            return new GenericCodeBook();
        }
        GenericCodeBook result = new GenericCodeBook();
        ArrayList<DataInstance> featureVector = new ArrayList<>(
                resultingConfiguration.length);
        for (int i = 0; i < resultingConfiguration.length; i++) {
            featureVector.add(centroids[i]);
        }
        result.setCodeBookSet(featureVector);
        return result;
    }

    /**
     * Loads the sample from a file.
     *
     * @param inFile Input file in feature descriptor format from OpenCV, which
     * is essentially plain csv.
     * @param perc Float value that is the percentage of features to take.
     */
    private void loadFeaturesFromDescriptorFile(File inFile, float perc)
            throws Exception {
        // Extract data and append to the current sample.
        DataSet featureRepresentation = featureSample.cloneDefinition();
        Random randa = new Random();
        try (BufferedReader br = new BufferedReader(new InputStreamReader(
                new FileInputStream(inFile)));) {
            DataInstance instance = new DataInstance(featureSample);
            String s = br.readLine();
            while (s != null) {
                // Parse a single line as a feature.
                String[] items = s.split(",");
                for (int i = 0; i < items.length; i++) {
                    instance.fAttr[i] = Float.parseFloat(items[i]);
                }
                featureRepresentation.addDataInstance(instance);
                instance.embedInDataset(featureSample);
                s = br.readLine();
            }
            if (!featureRepresentation.isEmpty()) {
                for (DataInstance element : featureRepresentation.data) {
                    if (randa.nextFloat() < perc) {
                        featureSample.addDataInstance(element);
                    }
                }
            }
        } catch (Exception e) {
            System.err.println(e.getMessage());
        }
    }

    /**
     * Loads the sample from a directory.
     *
     * @param inDir Input directory.
     * @param perc Float value that is the percentage of features to take.
     */
    private void loadFeaturesFromDirectory(File inDir, float perc)
            throws Exception {
        File[] descFiles = inDir.listFiles(new DescFileNameFilter());
        File[] subdirectories = inDir.listFiles(new DirectoryFilter());
        if (recursive) {
            for (File dir : subdirectories) {
                loadFeaturesFromDirectory(dir, perc);
            }
        }
        for (File descFile : descFiles) {
            if (!tabuPathMap.containsKey(descFile.getAbsolutePath())) {
                loadFeaturesFromDescriptorFile(descFile, perc);
            }
        }
    }

    /**
     * Loads the sample from the current target.
     *
     * @param perc Float value that is the percentage of features to take.
     */
    public void getFeaturesFromTargetFiles(float perc)
            throws Exception {
        if (target.isDirectory()) {
            loadFeaturesFromDirectory(target, perc);
        } else {
            loadFeaturesFromDescriptorFile(target, perc);
        }
    }
}